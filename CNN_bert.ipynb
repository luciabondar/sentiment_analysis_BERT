{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnwGDmMpb_4z",
        "outputId": "b8a36ccf-b971-4311-ee87-2db02869d466"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpMhmJZgcL8x",
        "outputId": "5428e6cc-b8a0-48f8-f8a1-223009022a8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cPvnZetocPoI",
        "outputId": "4fd1ab42-903b-4188-cbcb-2736afa7deb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/drive/MyDrive/inflation_reports'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.chdir(\"/drive/MyDrive/inflation_reports\") \n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pjujyNncS3s"
      },
      "outputs": [],
      "source": [
        "path = \"/drive/MyDrive/inflation_reports/dataset/data.csv\"\n",
        "df = pd.read_csv(path, encoding='latin-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVunUeTccbMx"
      },
      "outputs": [],
      "source": [
        "def to_sentiment(rating):\n",
        "\n",
        "  if rating == 'negative':\n",
        "    return 0\n",
        "  elif rating == 'neutral':\n",
        "    return 1\n",
        "  elif rating == 'positive':\n",
        "    return 2\n",
        "\n",
        "df['score'] = df.sentiment.apply(to_sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5Rvtrmecofm"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "df_train, df_test = train_test_split(df, test_size=0.2, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7utDRTFCc8QL"
      },
      "outputs": [],
      "source": [
        "train_sentences = list(df_train['sentence'].values)\n",
        "train_labels = list(df_train['score'].values)\n",
        "\n",
        "dev_sentences = list(df_test['sentence'].values)\n",
        "dev_labels = list(df_test['score'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRrO15dBdXcU"
      },
      "outputs": [],
      "source": [
        "!pip install -qq transformers\n",
        "\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW\n",
        "\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MAxsj-sdqQx",
        "outputId": "269f25f7-43ff-4dd8-fcc4-73490f1a3838"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(26, 141),\n",
              " (25, 137),\n",
              " (22, 133),\n",
              " (23, 131),\n",
              " (24, 123),\n",
              " (18, 119),\n",
              " (28, 119),\n",
              " (20, 118),\n",
              " (21, 115),\n",
              " (15, 113),\n",
              " (27, 111),\n",
              " (19, 109),\n",
              " (16, 107),\n",
              " (17, 107),\n",
              " (30, 103),\n",
              " (29, 100),\n",
              " (31, 98),\n",
              " (32, 96),\n",
              " (14, 95),\n",
              " (33, 88),\n",
              " (35, 82),\n",
              " (12, 82),\n",
              " (34, 81),\n",
              " (13, 80),\n",
              " (39, 65),\n",
              " (38, 63),\n",
              " (36, 62),\n",
              " (40, 57),\n",
              " (10, 56),\n",
              " (37, 56),\n",
              " (41, 53),\n",
              " (11, 51),\n",
              " (45, 50),\n",
              " (42, 48),\n",
              " (50, 46),\n",
              " (46, 44),\n",
              " (48, 44),\n",
              " (47, 43),\n",
              " (43, 39),\n",
              " (49, 35),\n",
              " (51, 35),\n",
              " (44, 27),\n",
              " (54, 26),\n",
              " (55, 25),\n",
              " (8, 25),\n",
              " (57, 22),\n",
              " (9, 21),\n",
              " (56, 20),\n",
              " (52, 18),\n",
              " (59, 18),\n",
              " (7, 18),\n",
              " (53, 18),\n",
              " (61, 17),\n",
              " (58, 16),\n",
              " (6, 14),\n",
              " (66, 14),\n",
              " (62, 14),\n",
              " (64, 14),\n",
              " (65, 12),\n",
              " (68, 11),\n",
              " (60, 11),\n",
              " (69, 11),\n",
              " (63, 10),\n",
              " (70, 9),\n",
              " (5, 6),\n",
              " (72, 5),\n",
              " (77, 5),\n",
              " (67, 5),\n",
              " (71, 4),\n",
              " (76, 4),\n",
              " (4, 3),\n",
              " (74, 3),\n",
              " (73, 2),\n",
              " (75, 2),\n",
              " (79, 1),\n",
              " (80, 1),\n",
              " (96, 1),\n",
              " (3, 1),\n",
              " (98, 1),\n",
              " (109, 1),\n",
              " (90, 1),\n",
              " (83, 1),\n",
              " (92, 1),\n",
              " (153, 1),\n",
              " (122, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "#choose max_length for bert model based on the input length\n",
        "\n",
        "max_length = 0\n",
        "list_len=[]\n",
        "for sentence in train_sentences:\n",
        "    #print(sentence)\n",
        "    length = len(tokenizer.tokenize(sentence))\n",
        "    list_len.append(length)\n",
        "    \n",
        "from collections import Counter\n",
        "Counter(list_len).most_common(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIEBir-CduNZ"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(train_labels)\n",
        "encoded_labels = le.transform(train_labels)\n",
        "encoded_test_labels = le.transform(dev_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciq4K4Zwdxfy",
        "outputId": "b986219e-68f9-4b34-8e2a-9506a0e99966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  In Russia , Raisio 's Food Division 's home market stretches all the way to Vladivostok .\n",
            "Token IDs: tensor([  101,  1130,  2733,   117, 20089, 23652,   112,   188,  6702,  1784,\n",
            "          112,   188,  1313,  2319, 14664,  1155,  1103,  1236,  1106, 20868,\n",
            "        15435, 12223,  1377,   119,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
          ]
        }
      ],
      "source": [
        "def encoder_generator(sentences,labels):\n",
        "    \n",
        "    sent_index = []\n",
        "    input_ids = []\n",
        "    attention_masks =[]\n",
        "\n",
        "    for index,sent in enumerate(sentences):\n",
        "        \n",
        "        sent_index.append(index)\n",
        "        \n",
        "        encoded_dict = tokenizer.encode_plus(sent,\n",
        "                                             add_special_tokens=True,\n",
        "                                             max_length=500,\n",
        "                                             pad_to_max_length=True,\n",
        "                                             truncation = True,\n",
        "                                             return_attention_mask=True,\n",
        "                                             return_tensors='pt')\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids,dim=0)\n",
        "    attention_masks = torch.cat(attention_masks,dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "    sent_index = torch.tensor(sent_index)\n",
        "\n",
        "    return sent_index,input_ids,attention_masks,labels\n",
        "\n",
        "train_sent_index,train_input_ids,train_attention_masks,train_encoded_label_tensors = encoder_generator(train_sentences,encoded_labels)\n",
        "dev_sent_index,dev_input_ids,dev_attention_masks,dev_encoded_label_tensors = encoder_generator(dev_sentences,encoded_test_labels)\n",
        "print('Original: ', train_sentences[0])\n",
        "print('Token IDs:', train_input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1UHmJyNd4KI",
        "outputId": "64218246-97fa-47e9-ab13-cb17066be536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data samples is 3876\n",
            "valid data samples is 970\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset,random_split\n",
        "\n",
        "train_dataset = TensorDataset(train_input_ids,train_attention_masks,train_encoded_label_tensors)\n",
        "dev_dataset = TensorDataset(dev_input_ids,dev_attention_masks,dev_encoded_label_tensors)\n",
        "\n",
        "\n",
        "print('train data samples is {}'.format(len(train_dataset)))\n",
        "print(\"valid data samples is {}\".format(len(dev_dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDoCN6Jpd7TJ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader,RandomSampler,SequentialSampler\n",
        "\n",
        "bs=4\n",
        "\n",
        "train_data_loader = DataLoader(train_dataset,\n",
        "                              sampler=RandomSampler(train_dataset),\n",
        "                              batch_size=bs)\n",
        "valid_data_loader = DataLoader(dev_dataset,\n",
        "                              sampler=RandomSampler(dev_dataset),\n",
        "                              batch_size=bs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reCHIzGod-8P",
        "outputId": "eac21611-c3b4-4076-fcaa-6cb7fd238687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict = False)\n",
        "bert_model = bert_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTGRUSentiment(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = bert\n",
        "        \n",
        "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
        "        \n",
        "        self.rnn = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers = n_layers,\n",
        "                          bidirectional = bidirectional,\n",
        "                          batch_first = True,\n",
        "                          dropout = 0 if n_layers < 2 else dropout)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        #text = [batch size, sent len]\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            embedded = self.bert(text)[0]\n",
        "                \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        _, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #hidden = [n layers * n directions, batch size, emb dim]\n",
        "        \n",
        "        if self.rnn.bidirectional:\n",
        "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1,:,:])\n",
        "                \n",
        "        #hidden = [batch size, hid dim]\n",
        "        \n",
        "        output = self.out(hidden)\n",
        "        \n",
        "        #output = [batch size, out dim]\n",
        "        \n",
        "        return output"
      ],
      "metadata": {
        "id": "oRXimZ7d6C4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUM89npSfU6I"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_input = nn.Linear(embedding_dim,embedding_dim)\n",
        "        \n",
        "        self.conv_0 = nn.Conv1d(in_channels = embedding_dim, \n",
        "                                out_channels = n_filters, \n",
        "                                kernel_size = filter_sizes[0])\n",
        "        \n",
        "        self.conv_1 = nn.Conv1d(in_channels = embedding_dim, \n",
        "                                out_channels = n_filters, \n",
        "                                kernel_size = filter_sizes[1])\n",
        "        \n",
        "        self.conv_2 = nn.Conv1d(in_channels = embedding_dim, \n",
        "                                out_channels = n_filters, \n",
        "                                kernel_size = filter_sizes[2])\n",
        "        \n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, encoded):\n",
        "                \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        embedded = self.fc_input(encoded)\n",
        "        #print(embedded.shape)\n",
        "        \n",
        "        embedded = embedded.permute(0, 2, 1)\n",
        "        #print(embedded.shape)\n",
        "        \n",
        "        #embedded = [batch size, emb dim, sent len]\n",
        "        \n",
        "        conved_0 = F.relu(self.conv_0(embedded))\n",
        "        conved_1 = F.relu(self.conv_1(embedded))\n",
        "        conved_2 = F.relu(self.conv_2(embedded))\n",
        "            \n",
        "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
        "        \n",
        "        pooled_0 = F.max_pool1d(conved_0, conved_0.shape[2]).squeeze(2)\n",
        "        pooled_1 = F.max_pool1d(conved_1, conved_1.shape[2]).squeeze(2)\n",
        "        pooled_2 = F.max_pool1d(conved_2, conved_2.shape[2]).squeeze(2)\n",
        "        \n",
        "        #pooled_n = [batch size, n_fibatlters]\n",
        "        \n",
        "        cat = self.dropout(torch.cat((pooled_0, pooled_1, pooled_2), dim = 1))\n",
        "\n",
        "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
        "            \n",
        "        result =  self.fc(cat)\n",
        "        \n",
        "        #print(result.shape)\n",
        "        \n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym1bBZmpfWK3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "f431df5d-83e3-4c1b-81fc-e89456ac2b06"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-77d53ba22367>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mltsm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m768\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mltsm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mltsm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-f9a5d58fbe8a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, num_labels, rnn_hidden_size, num_layers, bidirectional, dropout)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBertLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
          ]
        }
      ],
      "source": [
        "EMBEDDING_DIM = 768\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [2,3,5]\n",
        "OUTPUT_DIM = len(le.classes_)\n",
        "DROPOUT = 0.3\n",
        "PAD_IDX = tokenizer.pad_token_id\n",
        "\n",
        "cnn = CNN(EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
        "cnn = cnn.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cha9dMarfZ31"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model_prameters = list(bert_model.parameters())+list(cnn.parameters())\n",
        "\n",
        "optimizer = optim.Adam(model_prameters,lr=2e-5,eps=1e-8)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcgqCwGofw6X"
      },
      "outputs": [],
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    correct = max_preds.squeeze(1).eq(y)\n",
        "    return correct.sum() / torch.FloatTensor([y.shape[0]]).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvQ-49QDf1A1"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train():\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    bert_model.train()\n",
        "    cnn.train()\n",
        "    \n",
        "    for batch in tqdm(train_data_loader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        embedded = bert_model(b_input_ids,b_input_mask)[0]\n",
        "        \n",
        "        predictions = cnn(embedded)\n",
        "        #print(predictions.shape)\n",
        "        #print(b_labels.shape)\n",
        "        \n",
        "        loss = criterion(predictions, b_labels)\n",
        "        \n",
        "        acc = categorical_accuracy(predictions, b_labels)\n",
        "        #print(acc)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(train_data_loader), epoch_acc / len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNDah6MxgYZL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def predictions_labels(preds,labels):\n",
        "    pred = np.argmax(preds,axis=1).flatten()\n",
        "    label = labels.flatten()\n",
        "    return pred,label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7nIlTXrgbTa"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report,accuracy_score,f1_score\n",
        "def eval():\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    total_predictions = []\n",
        "    total_true = []\n",
        "    \n",
        "    all_true_labels = []\n",
        "    all_pred_labels = []\n",
        "    \n",
        "    bert_model.eval()\n",
        "    cnn.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in tqdm(valid_data_loader):\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            embedded = bert_model(b_input_ids,b_input_mask)[0]\n",
        "            predictions = cnn(embedded)\n",
        "            #print(predictions.shape)\n",
        "            #print(b_labels.shape)\n",
        "\n",
        "            loss = criterion(predictions, b_labels)\n",
        "            epoch_loss += loss.item()\n",
        "            \n",
        "            predictions = predictions.detach().cpu().numpy()\n",
        "\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "            pred,true = predictions_labels(predictions,label_ids)\n",
        "        \n",
        "            all_pred_labels.extend(pred)\n",
        "            all_true_labels.extend(true)\n",
        "\n",
        "    print(classification_report(all_pred_labels,all_true_labels))\n",
        "    avg_val_accuracy = accuracy_score(all_pred_labels,all_true_labels)\n",
        "    macro_f1_score = f1_score(all_pred_labels,all_true_labels,average='macro')\n",
        "    \n",
        "    avg_val_loss = epoch_loss/len(valid_data_loader)\n",
        "\n",
        "    print(\"accuracy = {0:.2f}\".format(avg_val_accuracy))\n",
        "            \n",
        "    return avg_val_loss,avg_val_accuracy,macro_f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JartbHHwgd2b"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgWZ6lQJgh2K",
        "outputId": "7a210edc-7a35-4262-d63f-fd6d3d45f33e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 969/969 [03:55<00:00,  4.11it/s]\n",
            "100%|██████████| 243/243 [00:18<00:00, 13.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.79      0.81       116\n",
            "           1       0.87      0.91      0.89       544\n",
            "           2       0.84      0.78      0.81       310\n",
            "\n",
            "    accuracy                           0.86       970\n",
            "   macro avg       0.85      0.83      0.84       970\n",
            "weighted avg       0.85      0.86      0.85       970\n",
            "\n",
            "accuracy = 0.86\n",
            "Epoch: 01 | Epoch Time: 4m 14s\n",
            "\tTrain Loss: 0.524 | Train Acc: 78.41%\n",
            "\t Val. Loss: 0.365 |  Val. Acc: 85.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 969/969 [03:55<00:00,  4.11it/s]\n",
            "100%|██████████| 243/243 [00:18<00:00, 13.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.80      0.84       123\n",
            "           1       0.82      0.92      0.87       512\n",
            "           2       0.85      0.73      0.79       335\n",
            "\n",
            "    accuracy                           0.84       970\n",
            "   macro avg       0.85      0.82      0.83       970\n",
            "weighted avg       0.84      0.84      0.84       970\n",
            "\n",
            "accuracy = 0.84\n",
            "Epoch: 02 | Epoch Time: 4m 14s\n",
            "\tTrain Loss: 0.260 | Train Acc: 90.40%\n",
            "\t Val. Loss: 0.391 |  Val. Acc: 83.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 969/969 [03:55<00:00,  4.11it/s]\n",
            "100%|██████████| 243/243 [00:18<00:00, 13.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.81      0.83       118\n",
            "           1       0.89      0.91      0.90       559\n",
            "           2       0.83      0.82      0.82       293\n",
            "\n",
            "    accuracy                           0.87       970\n",
            "   macro avg       0.86      0.84      0.85       970\n",
            "weighted avg       0.87      0.87      0.87       970\n",
            "\n",
            "accuracy = 0.87\n",
            "Epoch: 03 | Epoch Time: 4m 14s\n",
            "\tTrain Loss: 0.130 | Train Acc: 95.72%\n",
            "\t Val. Loss: 0.409 |  Val. Acc: 86.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 969/969 [03:55<00:00,  4.11it/s]\n",
            "100%|██████████| 243/243 [00:18<00:00, 13.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.83      0.85       116\n",
            "           1       0.91      0.89      0.90       584\n",
            "           2       0.79      0.84      0.82       270\n",
            "\n",
            "    accuracy                           0.87       970\n",
            "   macro avg       0.86      0.85      0.85       970\n",
            "weighted avg       0.87      0.87      0.87       970\n",
            "\n",
            "accuracy = 0.87\n",
            "Epoch: 04 | Epoch Time: 4m 14s\n",
            "\tTrain Loss: 0.092 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.427 |  Val. Acc: 86.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 969/969 [03:55<00:00,  4.11it/s]\n",
            "100%|██████████| 243/243 [00:18<00:00, 13.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.85      0.83       103\n",
            "           1       0.96      0.81      0.88       675\n",
            "           2       0.62      0.93      0.74       192\n",
            "\n",
            "    accuracy                           0.84       970\n",
            "   macro avg       0.79      0.87      0.82       970\n",
            "weighted avg       0.88      0.84      0.85       970\n",
            "\n",
            "accuracy = 0.84\n",
            "Epoch: 05 | Epoch Time: 4m 14s\n",
            "\tTrain Loss: 0.064 | Train Acc: 98.07%\n",
            "\t Val. Loss: 0.760 |  Val. Acc: 84.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 969/969 [03:55<00:00,  4.11it/s]\n",
            "100%|██████████| 243/243 [00:18<00:00, 13.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.93      0.82        86\n",
            "           1       0.94      0.86      0.89       623\n",
            "           2       0.77      0.85      0.81       261\n",
            "\n",
            "    accuracy                           0.86       970\n",
            "   macro avg       0.81      0.88      0.84       970\n",
            "weighted avg       0.87      0.86      0.86       970\n",
            "\n",
            "accuracy = 0.86\n",
            "Epoch: 06 | Epoch Time: 4m 14s\n",
            "\tTrain Loss: 0.055 | Train Acc: 98.12%\n",
            "\t Val. Loss: 0.574 |  Val. Acc: 86.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 969/969 [03:55<00:00,  4.11it/s]\n",
            "100%|██████████| 243/243 [00:18<00:00, 13.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.88      0.81        94\n",
            "           1       0.91      0.86      0.89       606\n",
            "           2       0.76      0.81      0.79       270\n",
            "\n",
            "    accuracy                           0.85       970\n",
            "   macro avg       0.81      0.85      0.83       970\n",
            "weighted avg       0.86      0.85      0.85       970\n",
            "\n",
            "accuracy = 0.85\n",
            "Epoch: 07 | Epoch Time: 4m 14s\n",
            "\tTrain Loss: 0.041 | Train Acc: 98.81%\n",
            "\t Val. Loss: 0.613 |  Val. Acc: 84.95%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 969/969 [03:55<00:00,  4.11it/s]\n",
            "100%|██████████| 243/243 [00:18<00:00, 13.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.84       100\n",
            "           1       0.93      0.86      0.90       616\n",
            "           2       0.76      0.87      0.81       254\n",
            "\n",
            "    accuracy                           0.87       970\n",
            "   macro avg       0.83      0.87      0.85       970\n",
            "weighted avg       0.87      0.87      0.87       970\n",
            "\n",
            "accuracy = 0.87\n",
            "Epoch: 08 | Epoch Time: 4m 14s\n",
            "\tTrain Loss: 0.037 | Train Acc: 98.76%\n",
            "\t Val. Loss: 0.551 |  Val. Acc: 86.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 969/969 [03:55<00:00,  4.11it/s]\n",
            "100%|██████████| 243/243 [00:18<00:00, 13.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.87      0.84       102\n",
            "           1       0.87      0.90      0.89       554\n",
            "           2       0.84      0.77      0.81       314\n",
            "\n",
            "    accuracy                           0.86       970\n",
            "   macro avg       0.84      0.85      0.84       970\n",
            "weighted avg       0.86      0.86      0.85       970\n",
            "\n",
            "accuracy = 0.86\n",
            "Epoch: 09 | Epoch Time: 4m 14s\n",
            "\tTrain Loss: 0.031 | Train Acc: 99.02%\n",
            "\t Val. Loss: 0.661 |  Val. Acc: 85.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 969/969 [03:55<00:00,  4.11it/s]\n",
            "100%|██████████| 243/243 [00:18<00:00, 13.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.79      0.82       117\n",
            "           1       0.91      0.89      0.90       584\n",
            "           2       0.79      0.85      0.82       269\n",
            "\n",
            "    accuracy                           0.87       970\n",
            "   macro avg       0.85      0.84      0.85       970\n",
            "weighted avg       0.87      0.87      0.87       970\n",
            "\n",
            "accuracy = 0.87\n",
            "Epoch: 10 | Epoch Time: 4m 13s\n",
            "\tTrain Loss: 0.042 | Train Acc: 98.66%\n",
            "\t Val. Loss: 0.630 |  Val. Acc: 86.70%\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "epochs = 10\n",
        "\n",
        "best_macro_f1 = float('0')\n",
        "\n",
        "history = defaultdict(list)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    train_loss,train_acc = train()\n",
        "    valid_loss,valid_acc,macro_f1 = eval()\n",
        "    end_time = time.time()\n",
        "    \n",
        "        \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "        \n",
        "    if macro_f1 > best_macro_f1:\n",
        "        best_macro_f1 = macro_f1\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(valid_acc.item())\n",
        "    history['val_loss'].append(valid_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "ZxGwMXCbmvON",
        "outputId": "a73e5f78-b56c-49e2-a59b-2bb6aa82d5ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7840557275541795, 0.9040247678018576, 0.957172342621259, 0.9713622291021672, 0.9806501547987616, 0.9811661506707946, 0.9881320949432405, 0.9876160990712074, 0.9901960784313726, 0.9865841073271414]\n",
            "[0.8556701030927835, 0.8381443298969072, 0.865979381443299, 0.8680412371134021, 0.8412371134020619, 0.8618556701030928, 0.8494845360824742, 0.865979381443299, 0.8556701030927835, 0.8670103092783505]\n",
            "tensor([0.7841, 0.9040, 0.9572, 0.9714, 0.9807, 0.9812, 0.9881, 0.9876, 0.9902,\n",
            "        0.9866])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(history['train_acc'])\n",
        "print(history['val_acc'])\n",
        "\n",
        "new_tensor = torch.tensor(history['train_acc'], device = 'cpu')\n",
        "print(new_tensor)\n",
        "\n",
        "plt.plot(new_tensor, label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0.5, 1]);"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN bert.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}